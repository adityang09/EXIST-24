{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8364535,"sourceType":"datasetVersion","datasetId":4708689}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Pre-Processing","metadata":{}},{"cell_type":"markdown","source":"* 3 November 2023 Registration open.\n* 4 March 2024 Training and development sets available.\n* 15 April 2024 Test set available.\n* 22 April 2024 Registration closes.\n> *** 6 May 2024 Runs submission due to organizers.****\n* 20 May 2024 Results notification to participants.\n* 3 June 2024 Submission of Working Notes by participants.\n* 19 June 2024 Notification of acceptance (peer-reviews).\n* 3 July 2024 Camera-ready participant papers due to organizers.\n* 9-12 September 2024 EXIST 2024 at CLEF Conference.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom transformers import logging, AutoTokenizer, AutoModel,AutoModelForSequenceClassification\nfrom sklearn.metrics import precision_recall_fscore_support,accuracy_score\nfrom functools import partial\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_fscore_support\nimport json\nimport os\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport logging\nfrom datetime import datetime\nimport sys\nfrom contextlib import redirect_stdout\nfrom io import StringIO\nimport json\nimport torch.nn.parallel\n# from ai21 import AI21Client\n# from ai21.models import ParaphraseStyleType","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-09T09:55:31.922197Z","iopub.execute_input":"2024-05-09T09:55:31.922527Z","iopub.status.idle":"2024-05-09T09:55:40.036489Z","shell.execute_reply.started":"2024-05-09T09:55:31.9225Z","shell.execute_reply":"2024-05-09T09:55:40.035427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_json(\"/kaggle/input/exist-2024/EXIST2024_training.json\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:40.038365Z","iopub.execute_input":"2024-05-09T09:55:40.039296Z","iopub.status.idle":"2024-05-09T09:55:42.353974Z","shell.execute_reply.started":"2024-05-09T09:55:40.039262Z","shell.execute_reply":"2024-05-09T09:55:42.352936Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_json(\"/kaggle/input/exist-2024/EXIST2023_test_clean.json\")\ndf_test = df_test.T\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:42.355089Z","iopub.execute_input":"2024-05-09T09:55:42.35538Z","iopub.status.idle":"2024-05-09T09:55:43.168311Z","shell.execute_reply.started":"2024-05-09T09:55:42.355355Z","shell.execute_reply":"2024-05-09T09:55:43.167378Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train=df_train.T\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.17035Z","iopub.execute_input":"2024-05-09T09:55:43.170648Z","iopub.status.idle":"2024-05-09T09:55:43.226631Z","shell.execute_reply.started":"2024-05-09T09:55:43.170623Z","shell.execute_reply":"2024-05-09T09:55:43.22574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.22759Z","iopub.execute_input":"2024-05-09T09:55:43.227819Z","iopub.status.idle":"2024-05-09T09:55:43.233693Z","shell.execute_reply.started":"2024-05-09T09:55:43.227799Z","shell.execute_reply":"2024-05-09T09:55:43.232769Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dev=pd.read_json('/kaggle/input/exist-2024/EXIST2024_dev.json')\ndf_dev=df_dev.T\ndf_dev.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.234997Z","iopub.execute_input":"2024-05-09T09:55:43.235339Z","iopub.status.idle":"2024-05-09T09:55:43.575864Z","shell.execute_reply.started":"2024-05-09T09:55:43.235308Z","shell.execute_reply":"2024-05-09T09:55:43.574942Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[\"split\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.577211Z","iopub.execute_input":"2024-05-09T09:55:43.577602Z","iopub.status.idle":"2024-05-09T09:55:43.590489Z","shell.execute_reply.started":"2024-05-09T09:55:43.57755Z","shell.execute_reply":"2024-05-09T09:55:43.589586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def assign_labels(dfrow,task=\"task1\"):\n    annot_labels=dfrow[f'labels_{task}']\n    if annot_labels.count(\"YES\")>=3:\n        return \"sexist\"\n    else:\n        return \"nonsexist\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.591752Z","iopub.execute_input":"2024-05-09T09:55:43.592234Z","iopub.status.idle":"2024-05-09T09:55:43.597343Z","shell.execute_reply.started":"2024-05-09T09:55:43.592207Z","shell.execute_reply":"2024-05-09T09:55:43.596414Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def majority_voting_df(df,task=\"task1\"):\n    df[f'{task}']=df.apply(assign_labels,axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.598607Z","iopub.execute_input":"2024-05-09T09:55:43.598945Z","iopub.status.idle":"2024-05-09T09:55:43.607074Z","shell.execute_reply.started":"2024-05-09T09:55:43.598913Z","shell.execute_reply":"2024-05-09T09:55:43.606134Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_df(df,task=\"task1\",shuffle=True):\n    \"Set shuffle as False for test\"\n#     tasks = ['task1','task2','task3']\n    common_cols = ['lang','number_annotators', 'annotators',\n       'gender_annotators', 'age_annotators', 'ethnicities_annotators',\n       'study_levels_annotators', 'countries_annotators','labels_task1','labels_task2','labels_task3','split']\n#     common_cols.extend([\"labels_\"+col for col in tasks if col!=task])\n    df.drop(common_cols,axis=1,inplace = True)\n    \n    #Renaming task to label\n    df = df.rename(columns={task:\"label\"})\n    \n    #Shuffling\n    ##Fisher-Yates Algorithm\n    if shuffle is True:\n        num_rows = len(df)\n        indices = np.arange(num_rows)\n\n        for i in range(num_rows - 1, 0, -1):\n            j = np.random.randint(0, i + 1)\n            indices[i], indices[j] = indices[j], indices[i]\n\n        shuffled_df = df.iloc[indices].reset_index(drop=True)\n        return shuffled_df\n    else:\n        return df\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.610686Z","iopub.execute_input":"2024-05-09T09:55:43.610979Z","iopub.status.idle":"2024-05-09T09:55:43.61918Z","shell.execute_reply.started":"2024-05-09T09:55:43.610952Z","shell.execute_reply":"2024-05-09T09:55:43.618325Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_val_split(df,splitval):\n    split = int(len(df)*splitval)\n    return df[:split],df[split:]","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.620163Z","iopub.execute_input":"2024-05-09T09:55:43.620423Z","iopub.status.idle":"2024-05-09T09:55:43.632392Z","shell.execute_reply.started":"2024-05-09T09:55:43.620401Z","shell.execute_reply":"2024-05-09T09:55:43.631574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = majority_voting_df(df_train,\"task1\")\ndf_train = preprocess_df(df_train)\n# df_train,df_val = train_val_split(df_train,0.8)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.633403Z","iopub.execute_input":"2024-05-09T09:55:43.633683Z","iopub.status.idle":"2024-05-09T09:55:43.776355Z","shell.execute_reply.started":"2024-05-09T09:55:43.633653Z","shell.execute_reply":"2024-05-09T09:55:43.775358Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dev = majority_voting_df(df_dev,\"task1\")\ndf_dev = preprocess_df(df_dev,shuffle=False)\n# df_train,df_val = train_val_split(df_train,0.8)\ndf_dev.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.77759Z","iopub.execute_input":"2024-05-09T09:55:43.777866Z","iopub.status.idle":"2024-05-09T09:55:43.802105Z","shell.execute_reply.started":"2024-05-09T09:55:43.777842Z","shell.execute_reply":"2024-05-09T09:55:43.801227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.803428Z","iopub.execute_input":"2024-05-09T09:55:43.80378Z","iopub.status.idle":"2024-05-09T09:55:43.812515Z","shell.execute_reply.started":"2024-05-09T09:55:43.803749Z","shell.execute_reply":"2024-05-09T09:55:43.811736Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.drop(['lang', 'number_annotators', 'annotators',\n       'gender_annotators', 'age_annotators', 'ethnicities_annotators',\n       'study_levels_annotators', 'countries_annotators', 'split'],axis = 1,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.813626Z","iopub.execute_input":"2024-05-09T09:55:43.813998Z","iopub.status.idle":"2024-05-09T09:55:43.822589Z","shell.execute_reply.started":"2024-05-09T09:55:43.813966Z","shell.execute_reply":"2024-05-09T09:55:43.821722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.823826Z","iopub.execute_input":"2024-05-09T09:55:43.824162Z","iopub.status.idle":"2024-05-09T09:55:43.840154Z","shell.execute_reply.started":"2024-05-09T09:55:43.824137Z","shell.execute_reply":"2024-05-09T09:55:43.839269Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:43.841099Z","iopub.execute_input":"2024-05-09T09:55:43.841408Z","iopub.status.idle":"2024-05-09T09:55:43.853348Z","shell.execute_reply.started":"2024-05-09T09:55:43.841384Z","shell.execute_reply":"2024-05-09T09:55:43.852554Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_val['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:59.280869Z","iopub.execute_input":"2024-05-09T09:55:59.281583Z","iopub.status.idle":"2024-05-09T09:55:59.285695Z","shell.execute_reply.started":"2024-05-09T09:55:59.281549Z","shell.execute_reply":"2024-05-09T09:55:59.28455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LEN_TRAIN,LEN_TEST = len(df_train),len(df_dev)\nLEN_TRAIN,LEN_TEST ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:08.139066Z","iopub.execute_input":"2024-05-09T09:56:08.139687Z","iopub.status.idle":"2024-05-09T09:56:08.146146Z","shell.execute_reply.started":"2024-05-09T09:56:08.139655Z","shell.execute_reply":"2024-05-09T09:56:08.14502Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train_json= df_train.to_json(orient='records') \nlabel_dict={'nonsexist':0,'sexist':1}","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:13.332135Z","iopub.execute_input":"2024-05-09T09:56:13.332482Z","iopub.status.idle":"2024-05-09T09:56:13.355457Z","shell.execute_reply.started":"2024-05-09T09:56:13.332457Z","shell.execute_reply":"2024-05-09T09:56:13.354529Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_json= df_dev.to_json(orient='records')#ACTUALLY TEST NOT VAL","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:13.872196Z","iopub.execute_input":"2024-05-09T09:56:13.872997Z","iopub.status.idle":"2024-05-09T09:56:13.880131Z","shell.execute_reply.started":"2024-05-09T09:56:13.872967Z","shell.execute_reply":"2024-05-09T09:56:13.879082Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Transformer(nn.Module):\n\n    def __init__(self, base_model, num_classes, method,args):\n        super().__init__()\n        self.args=args\n        self.base_model = base_model\n        self.num_classes = num_classes\n        self.method = method\n        self.hidden_size  = base_model.config.hidden_size\n        #self.linear = nn.Linear(base_model.config.hidden_size, num_classes)\n        self.linear = nn.Linear(self.hidden_size*2, num_classes)\n        self.linear_adjust_dim=nn.Linear(2048,1024)\n        self.dropout = nn.Dropout(args.dropout)\n        for param in base_model.parameters():\n            param.requires_grad_(True)\n            \n        if torch.cuda.device_count() > 1:\n            print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n            self.base_model = nn.DataParallel(self.base_model)\n            \n    def word_level_attention(self,lhs):\n        qq=lhs.float().to(self.args.device)\n        attention_weights=nn.Linear(self.hidden_size,1).to(self.args.device)(qq).tanh()\n        attention_weights=attention_weights.squeeze(dim=-1)\n        attention_weights=torch.nn.functional.softmax(attention_weights,dim=1)\n        attention_weights=torch.unsqueeze(attention_weights,dim=-1)*qq\n        word_level_attention=torch.sum(attention_weights,dim=1)\n        return word_level_attention\n        \n    def forward(self, inputs):\n        raw_outputs = self.base_model(**inputs)\n        hiddens = raw_outputs.last_hidden_state.to(self.args.device)\n        cls_feats = hiddens[:, 0, :].to(self.args.device)\n        if self.method in ['ce', 'scl']:\n            label_feats = None\n            word_attention=self.word_level_attention(hiddens)\n            concatenated_feats=torch.concat((cls_feats,word_attention),dim=1)\n            #predicts = self.linear(self.dropout(cls_feats))\n            predicts = self.linear(self.dropout(concatenated_feats))\n\n        else:\n            label_feats = hiddens[:, 1:self.num_classes+1, :]\n            predicts = torch.einsum('bd,bcd->bc', cls_feats, label_feats)\n            word_attention=self.word_level_attention(hiddens)\n            concatenated_feats=torch.concat((cls_feats,word_attention),dim=1)\n            #print(f\"DualCL Dim Concated:Shape is {concatenated_feats.shape}\")\n            dim_concat_feats=self.linear_adjust_dim(concatenated_feats)\n            #print(f\"DualCL Dim Adjusted :Shape is {dim_concat_feats.shape}\")\n            predicts = torch.einsum('bd,bcd->bc', dim_concat_feats, label_feats)\n        outputs = {\n            'predicts': predicts,\n            'cls_feats': cls_feats,\n            'hiddens':hiddens,\n            'label_feats': label_feats\n        }\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:14.5837Z","iopub.execute_input":"2024-05-09T09:56:14.58406Z","iopub.status.idle":"2024-05-09T09:56:14.599788Z","shell.execute_reply.started":"2024-05-09T09:56:14.584033Z","shell.execute_reply":"2024-05-09T09:56:14.598949Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Instructor:\n\n    def __init__(self, args):\n        self.args = args\n        #self.logger = logger\n        #self.logger.info('> creating model {}'.format(args.model_name))\n        if args.model_name == 'bert':\n            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n            base_model = AutoModel.from_pretrained('bert-base-uncased')\n        elif args.model_name == 'roberta':\n            self.tokenizer = AutoTokenizer.from_pretrained('roberta-base', add_prefix_space=True)\n            base_model = AutoModel.from_pretrained('roberta-base')\n        elif args.model_name == 'bertweet':\n            self.tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"NLP-LTU/bertweet-large-sexism-detector\", add_prefix_space=True)\n            base_model = AutoModel.from_pretrained(\"NLP-LTU/bertweet-large-sexism-detector\")\n        elif args.model_name == 'mbert':\n            self.tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n            base_model = AutoModel.from_pretrained(\"google-bert/bert-base-multilingual-cased\")\n        elif args.model_name == 't5':\n            self.tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n            base_model = AutoModel.from_pretrained(\"google/flan-t5-small\")\n        elif args.model_name=='xlm-r':\n            self.tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n            base_model = AutoModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n        elif args.model_name == 'xlm-r-large':\n            self.tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-large\")\n            base_model = AutoModel.from_pretrained(\"FacebookAI/xlm-roberta-large\")\n        else:\n            raise ValueError('unknown model')\n            \n        self.model = Transformer(base_model, args.num_classes, args.method,args)\n        self.model.to(args.device)\n        if args.device.type == 'cuda':\n            print('> cuda memory allocated: {}'.format(torch.cuda.memory_allocated(args.device.index)))\n        self._print_args()\n        \n    def eval_model(self,ytrue,ypred):\n        report = classification_report(ytrue,ypred )\n        print(report)\n\n        f1= precision_recall_fscore_support( ytrue,ypred , average='binary')\n        print(\"f1 :\" , f1)\n        accuracy = accuracy_score(ytrue,ypred, )\n        print(\"Accuracy :\" , accuracy)\n\n    def _print_args(self):\n        print('> training arguments:')\n        for arg in vars(self.args):\n            print(f\">>> {arg}: {getattr(self.args, arg)}\")\n            \n    def max_performance(self,outputs_prob,ytrue):\n        complete = int(LEN_TEST / self.args.test_batch_size)\n        pred_1 = np.concatenate([t.cpu().numpy() for t in outputs_prob[:complete]])\n        pred_2 = outputs_prob[complete].cpu().numpy()\n\n        #print(f\"Y true shape:{ytrue.shape}\")\n        outputs_prob= np.concatenate((pred_1, pred_2))\n        #print(f\"outputs_prob shape:{outputs_prob.shape}\")\n        start=time.time()\n        m = nn.Softmax(dim=1)\n        output_softmax=m(torch.from_numpy(outputs_prob))\n        #print(f\"Output softmax shape:{output_softmax.shape}\")\n        y_1=output_softmax[:,1].cpu()#Extracing elements from 1st index\n        #print(f\"After extracting shape:{y_1.shape}\")\n        max = 0\n        index = 0.1\n        for i in range(9000):\n            value = 0.1 + i*0.0001\n            y_pred1 = np.where(y_1>value, 1, 0)\n            f1_macro = precision_recall_fscore_support( ytrue, y_pred1 , average='macro',zero_division=1)\n            #acc = accuracy_score( ytrue, y_pred1 )\n            if f1_macro[2] > max :\n                max = f1_macro[2]\n                index = value\n        end=time.time()\n        print(\"Max Performance\")\n        print(f\"f1 macro: {max} at threshold {index}\")\n        print(f\"Finished in {end-start} seconds\")\n\n    def _train(self, dataloader, criterion, optimizer):\n        train_loss, n_correct, n_train = 0, 0, 0\n        self.model.train()\n        for inputs, targets in tqdm(dataloader, disable=self.args.backend, ascii=' >='):\n            inputs = {k: v.to(self.args.device) for k, v in inputs.items()}\n            targets = targets.to(self.args.device)\n            outputs = self.model(inputs)\n            loss = criterion(outputs, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * targets.size(0)\n            n_correct += (torch.argmax(outputs['predicts'], -1) == targets).sum().item()\n            n_train += targets.size(0)\n        return train_loss / n_train, n_correct / n_train\n\n    def _test(self, dataloader, criterion):\n        test_loss, n_correct, n_test = 0, 0, 0\n        m = nn.Softmax(dim=1)\n        self.model.eval()\n        l_yout=[]\n        l_ytrue=[]\n        stored_output=[]\n        with torch.no_grad():\n            for inputs, targets in tqdm(dataloader, disable=self.args.backend, ascii=' >='):\n                inputs = {k: v.to(self.args.device) for k, v in inputs.items()}\n                targets = targets.to(self.args.device)\n                outputs = self.model(inputs)\n                #print(\"Outputs: \",outputs)\n                #print(\"Predictions: \",outputs['predicts'])\n                pred=(torch.argmax(outputs['predicts'],-1)).cpu()\n                stored_output.append(outputs['predicts'])\n                l_yout.append(pred.numpy())\n                #print(\"ArgMax Pred: \",pred)\n                l_ytrue.append(targets.cpu().numpy())\n                \n                targets = targets.to(self.args.device)\n                #print(\"Targets: \",targets)\n                loss = criterion(outputs, targets)\n                test_loss += loss.item() * targets.size(0)\n                #print(f\"Sklearn accuracy is: {skacc}\")\n                n_correct += (torch.argmax(outputs['predicts'], -1) == targets).sum().item()\n                n_test += targets.size(0)\n        complete = int(LEN_TEST / self.args.test_batch_size)\n        print(\"LEN TEST: \",LEN_TEST)\n        pred_1=np.array(l_yout[:complete]).flatten()\n        pred_2=l_yout[complete]\n        ypred=np.append(pred_1,pred_2)\n        print(f\"Samples in Test Set: {len(ypred)}\")\n        true_1=np.array(l_ytrue[:complete]).flatten()\n        true_2=l_ytrue[complete]\n        ytrue=np.append(true_1,true_2)\n        \n        count1_ytrue=np.count_nonzero(ytrue==1)\n        count1_ypred=np.count_nonzero(ypred==1)\n        print(f\"Number of Sexist Examples in Testset: {count1_ytrue}\")\n        print(f\"Number of Sexist Predictions : {count1_ypred}\")\n        \n        self.eval_model(ytrue,ypred)\n#         self.max_performance(stored_output,ytrue)\n        return test_loss / n_test, n_correct / n_test\n\n    def run(self):\n        train_dataloader, test_dataloader = load_data(dataset=self.args.dataset,\n                                                      data_dir=self.args.data_dir,\n                                                      tokenizer=self.tokenizer,\n                                                      train_batch_size=self.args.train_batch_size,\n                                                      test_batch_size=self.args.test_batch_size,\n                                                      model_name=self.args.model_name,\n                                                      method=self.args.method,\n                                                      workers=0)\n        _params = filter(lambda p: p.requires_grad, self.model.parameters())\n        if self.args.method == 'ce':\n            criterion = CELoss()\n        elif self.args.method == 'scl':\n            criterion = SupConLoss(self.args.alpha, self.args.temp,self.args)\n        elif self.args.method == 'dualcl':\n            criterion = DualLoss(self.args.alpha, self.args.temp,self.args)\n        else:\n            raise ValueError('unknown method')\n        optimizer = torch.optim.AdamW(_params, lr=self.args.lr, weight_decay=self.args.decay)\n        best_loss, best_acc = 0, 0\n        self.best_model = self.model.state_dict()\n        for epoch in range(self.args.num_epoch):\n            train_loss, train_acc = self._train(train_dataloader, criterion, optimizer)\n            test_loss, test_acc= self._test(test_dataloader, criterion)\n            if test_acc > best_acc or (test_acc == best_acc and test_loss < best_loss):\n                best_acc, best_loss = test_acc, test_loss\n                self.best_model = self.model.state_dict()\n                \n            \n            \n            print('{}/{} - {:.2f}%'.format(epoch+1, self.args.num_epoch, 100*(epoch+1)/self.args.num_epoch))\n            print('[train] loss: {:.4f}, acc: {:.2f}'.format(train_loss, train_acc*100))\n            print('[test] loss: {:.4f}, acc: {:.2f}'.format(test_loss, test_acc*100))\n        if self.args.save_model:\n                torch.save(self.best_model, self.args.save_path)\n                print(f'Model saved to {self.args.save_path}')\n        print('best loss: {:.4f}, best acc: {:.2f}'.format(best_loss, best_acc*100))\n        return train_loss,train_acc,test_loss,test_acc","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:15.507205Z","iopub.execute_input":"2024-05-09T09:56:15.50757Z","iopub.status.idle":"2024-05-09T09:56:15.548449Z","shell.execute_reply.started":"2024-05-09T09:56:15.507536Z","shell.execute_reply":"2024-05-09T09:56:15.547394Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CELoss(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.xent_loss = nn.CrossEntropyLoss()\n\n    def forward(self, outputs, targets):\n        return self.xent_loss(outputs['predicts'], targets)\n\n\nclass SupConLoss(nn.Module):\n\n    def __init__(self, alpha, temp,args):\n        super().__init__()\n        self.xent_loss = nn.CrossEntropyLoss()\n        self.alpha = alpha\n        self.temp = temp\n        self.args=args\n#         self.hidden_size = 1024 if self.args.model_name=='bertweet' else 768\n        if self.args.model_name=='bertweet' or self.args.model_name=='xlm-r-large':\n            self.hidden_size = 1024\n        elif self.args.model_name=='mbert' or self.args.model_name=='xlm-r':\n            self.hidden_size = 768\n        elif self.args.model_name=='t5':\n            self.hidden_size = 512\n        else:\n            self.hidden_size = 512\n        \n        self.linear_adjust_dim=nn.Linear(self.hidden_size*2,self.hidden_size)\n        \n    def word_level_attention(self,lhs):\n        qq=lhs.float().to(self.args.device)\n        attention_weights=nn.Linear(self.hidden_size,1).to(self.args.device)(qq).tanh()\n        attention_weights=attention_weights.squeeze(dim=-1)\n        attention_weights=torch.nn.functional.softmax(attention_weights,dim=1)\n        attention_weights=torch.unsqueeze(attention_weights,dim=-1)*qq\n        word_level_attention=torch.sum(attention_weights,dim=1)\n        return word_level_attention\n    \n    def nt_xent_loss(self,anchor, target, labels, threshold=0.9):\n        '''\n        Updated loss function that ignores positive pairs below the threshold\n        1. Creates a mask of positives above the threshold\n        2. Loss Function, considering only positives above threshold in numerator\n           and both positives above threshold and negatives in denominator\n        '''\n        anchor=anchor.cpu()\n        target=target.cpu()\n        # Convert cosine similarity array to PyTorch tensor\n        #print(\"Cosine Similarity Matrix: \",cosine_sim)\n        # ONE: Create mask of positives above the threshold\n        with torch.no_grad():\n            cosine_sim = cosine_similarity(anchor, target)\n            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n            cosine_sim=torch.tensor(cosine_sim).to(device)\n            \n            labels = labels.unsqueeze(-1)\n            mask_positives = torch.eq(labels, labels.transpose(0, 1)) * (cosine_sim > threshold)\n            mask_negatives =  ~torch.eq(labels, labels.transpose(0, 1))\n\n        #print(\"Mask Positives(above thresh)\",mask_positives)\n        #print(\"Mask Negatives\",mask_negatives)\n        # TWO: Compute log probabilities for positives above threshold\n        logits_max, _ = torch.max(cosine_sim / self.temp, dim=1, keepdim=True)\n        logits = cosine_sim / self.temp - logits_max.detach()\n        exp_logits = torch.exp(logits)\n        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n        #print(\"All elements log prob: \",log_prob)\n        # THREE: Compute loss considering only positives in numerator and both positives and negatives in denominator\n        pos_mask_sum = mask_positives.sum(dim=1)\n        pos_mask_sum = torch.where(pos_mask_sum == 0, torch.ones_like(pos_mask_sum), pos_mask_sum)\n        pos_logits = (mask_positives * log_prob).sum(dim=1) / pos_mask_sum.detach()\n        #print(\"Positives above thresh logits: \",pos_logits)\n        neg_mask_sum = mask_negatives.sum(dim=1)\n        neg_mask_sum = torch.where(neg_mask_sum == 0, torch.ones_like(neg_mask_sum), neg_mask_sum)\n        neg_logits = (mask_negatives * log_prob).sum(dim=1) / neg_mask_sum.detach()\n        all_logits = (mask_positives * log_prob).sum(dim=1) + (mask_negatives * log_prob).sum(dim=1)\n        #print(\"Negative logits: \",neg_logits)\n        #print(\"Sum of pos and neg logits: \",all_logits)\n\n        # FOUR: Compute final loss by combining positives (above threshold) and negatives\n        alpha = 0.5  # Weighting factor for balancing the importance of positives in numerator and all samples in denominator\n        loss = -1 * (alpha * pos_logits + (1 - alpha) * all_logits).mean()\n        print(\"Loss: \",loss)\n\n        return loss\n\n    def forward(self, outputs, targets):\n        normed_cls_feats = F.normalize(outputs['cls_feats'], dim=-1)\n        ce_loss = (1 - self.alpha) * self.xent_loss(outputs['predicts'], targets)\n        self.linear_adjust_dim.to(self.args.device)\n        wla=self.word_level_attention(outputs['hiddens'])\n        concatenated_feats=torch.concat((normed_cls_feats,wla),dim=1)\n        dim_concat_feats=self.linear_adjust_dim(concatenated_feats)\n#         print(f\"DualCL Dim Concated:Shape is {concatenated_feats.shape}\")\n#         print(f\"DualCL Dim Adjusted :Shape is {dim_concat_feats.shape}\")\n\n        #cl_loss = self.alpha * self.nt_xent_loss(normed_cls_feats, normed_cls_feats, targets)\n        cl_loss = self.alpha * self.nt_xent_loss(dim_concat_feats,dim_concat_feats, targets)\n        return ce_loss + cl_loss\n\n    \nclass DualLoss(SupConLoss):\n\n    def __init__(self, alpha, temp,args):\n        super().__init__(alpha, temp,args)\n\n    def forward(self, outputs, targets):\n        normed_cls_feats = F.normalize(outputs['cls_feats'], dim=-1)\n        normed_label_feats = F.normalize(outputs['label_feats'], dim=-1)\n        normed_lhs_feats=F.normalize(outputs['hiddens'], dim=-1)\n        \n        self.linear_adjust_dim.to(self.args.device)\n        wla=self.word_level_attention(normed_lhs_feats)\n        concatenated_feats=torch.concat((normed_cls_feats,wla),dim=1)\n        dim_concat_feats=self.linear_adjust_dim(concatenated_feats)\n        \n        normed_pos_label_feats = torch.gather(normed_label_feats, dim=1, index=targets.reshape(-1, 1, 1).expand(-1, 1, normed_label_feats.size(-1))).squeeze(1)\n        ce_loss = (1 - self.alpha) * self.xent_loss(outputs['predicts'], targets)\n#         cl_loss_1 = 0.5 * self.alpha * self.nt_xent_loss(normed_pos_label_feats, normed_cls_feats, targets)\n#         cl_loss_2 = 0.5 * self.alpha * self.nt_xent_loss(normed_cls_feats, normed_pos_label_feats, targets)\n        #cl_loss_1 = 0.5 * self.alpha * self.nt_xent_loss(normed_pos_label_feats, dim_concat_feats, targets)\n        cl_loss_1 = 0.5 * self.alpha * self.nt_xent_loss(wla,wla, targets)\n        cl_loss_2= 0.5 * self.alpha * self.nt_xent_loss(dim_concat_feats, dim_concat_feats, targets)\n        return ce_loss + cl_loss_1 + cl_loss_2","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:16.033584Z","iopub.execute_input":"2024-05-09T09:56:16.033977Z","iopub.status.idle":"2024-05-09T09:56:16.063279Z","shell.execute_reply.started":"2024-05-09T09:56:16.033945Z","shell.execute_reply":"2024-05-09T09:56:16.062303Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyDataset(Dataset):\n    \n    def __init__(self, raw_data, label_dict,tokenizer, model_name, method):\n        label_list = list(label_dict.keys()) if method not in ['ce', 'scl'] else []\n        sep_token = ['[SEP]'] if model_name == 'bertweet' else ['</s>']\n        dataset = list()\n        for data in raw_data:\n            tokens = data['tweet'].lower().split(' ')\n            label_id = label_dict[data['label']]\n            dataset.append((label_list + sep_token + tokens, label_id))\n        self._dataset = dataset\n\n    def __getitem__(self, index):\n        return self._dataset[index]\n\n    def __len__(self):\n        return len(self._dataset)\n\n\ndef my_collate(batch, tokenizer, method, num_classes):\n    tokens, label_ids = map(list, zip(*batch))\n    text_ids = tokenizer(tokens,\n                         padding=True,\n                         truncation=True,\n                         max_length=128,\n                         is_split_into_words=True,\n                         add_special_tokens=True,\n                         return_tensors='pt')\n    if method not in ['ce', 'scl']:\n        positions = torch.zeros_like(text_ids['input_ids'])\n        positions[:, num_classes:] = torch.arange(0, text_ids['input_ids'].size(1)-num_classes)\n        text_ids['position_ids'] = positions\n    return text_ids, torch.tensor(label_ids)\n\ndef load_data(dataset, data_dir, tokenizer, train_batch_size, test_batch_size, model_name, method, workers):\n    if dataset=='exist':\n        train_data = json.loads(train_json)\n        test_data = json.loads(test_json)\n        label_dict={'nonsexist':0,'sexist':1} \n    else:\n        raise ValueError('unknown dataset')\n    trainset = MyDataset(train_data, label_dict, tokenizer, model_name, method)\n    testset = MyDataset(test_data, label_dict, tokenizer, model_name, method)\n    collate_fn = partial(my_collate, tokenizer=tokenizer, method=method, num_classes=len(label_dict))\n    train_dataloader = DataLoader(trainset, train_batch_size, shuffle=True, num_workers=workers, collate_fn=collate_fn, pin_memory=True)\n    test_dataloader = DataLoader(testset, test_batch_size, shuffle=False, num_workers=workers, collate_fn=collate_fn, pin_memory=True)\n    return train_dataloader, test_dataloader","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:16.564899Z","iopub.execute_input":"2024-05-09T09:56:16.565557Z","iopub.status.idle":"2024-05-09T09:56:16.578719Z","shell.execute_reply.started":"2024-05-09T09:56:16.565526Z","shell.execute_reply":"2024-05-09T09:56:16.577745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Args:\n    def __init__(self):\n        self.num_classes = 2\n        self.data_dir = 'data'\n        self.dataset = 'exist'  \n        \"\"\"\n        berTweet->1024 size vector\n        mBert->768 size vector\n        \"\"\"\n        self.model_name = 'xlm-r'     #'bertweet'  \n        self.method = 'scl'  \n        self.train_batch_size = 16\n        self.test_batch_size = 16\n        self.num_epoch = 30\n        self.lr = 1.0169734125025231e-06\n        self.decay = 0.0025948655072046897\n        self.dropout=0.36167949934204113\n        self.alpha = 0.5\n        self.temp =  0.09770519113292521\n        self.backend = False\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        #self.device=accelerator.device\n        self.save_model = True\n        self.save_path = 'best_model.pth'\n        \n        \n\nargs = Args()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:18.811999Z","iopub.execute_input":"2024-05-09T09:56:18.812995Z","iopub.status.idle":"2024-05-09T09:56:18.845722Z","shell.execute_reply.started":"2024-05-09T09:56:18.812957Z","shell.execute_reply":"2024-05-09T09:56:18.844722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import sys\n\n# instructor = Instructor(args)\n# instructor.run()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:20.0368Z","iopub.execute_input":"2024-05-09T09:56:20.037492Z","iopub.status.idle":"2024-05-09T09:56:20.041144Z","shell.execute_reply.started":"2024-05-09T09:56:20.037463Z","shell.execute_reply":"2024-05-09T09:56:20.040125Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# unhardcode max perf\n# remove train 100  \n# add code to save best weights on val\n\"\"\"TODO STILL\nrun these on final test at the very very end\naddress to cpu thingy to make it efficient\nrun inference on test set in another notebook\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:20.895202Z","iopub.execute_input":"2024-05-09T09:56:20.896236Z","iopub.status.idle":"2024-05-09T09:56:20.902182Z","shell.execute_reply.started":"2024-05-09T09:56:20.896195Z","shell.execute_reply":"2024-05-09T09:56:20.901189Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"captured_output = StringIO()\n\nwith redirect_stdout(captured_output):\n    instructor = Instructor(args)\n    instructor.run()\n\ncaptured_text = captured_output.getvalue()\n\nwith open('Task1_output.txt', 'w+') as f:\n    f.write(captured_text)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:56:23.065466Z","iopub.execute_input":"2024-05-09T09:56:23.066181Z","iopub.status.idle":"2024-05-09T10:01:19.277436Z","shell.execute_reply.started":"2024-05-09T09:56:23.066148Z","shell.execute_reply":"2024-05-09T10:01:19.276551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file = open(\"Task1_output.txt\",\"r\")\ntext=file.readlines()\nlen(text)\n\nprocessed_output=[]\nfor line in text:\n    if line.find(\"Loss:  tensor(\")==-1:\n        processed_output.append(line)\n        \nwith open(\"Task2_processed_output.txt\",\"w+\") as file:\n    file.writelines(processed_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:24.228606Z","iopub.execute_input":"2024-05-09T10:01:24.229517Z","iopub.status.idle":"2024-05-09T10:01:24.236193Z","shell.execute_reply.started":"2024-05-09T10:01:24.229476Z","shell.execute_reply":"2024-05-09T10:01:24.23539Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Using Saved Model for Predictions","metadata":{}},{"cell_type":"code","source":"# input_text = \"I hate women\"\n# inputs = tokenizer(input_text, return_tensors='pt').to(args.device)\n\n# with torch.no_grad():\n#     outputs = model(inputs)\n#     predictions = torch.argmax(outputs['predicts'], dim=1).cpu().numpy()\n\n# label_dict = {0: 'nonsexist', 1: 'sexist'}\n# predicted_label = label_dict[predictions[0]]\n# print(f\"Predicted label: {predicted_label}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:24.710076Z","iopub.execute_input":"2024-05-09T10:01:24.710677Z","iopub.status.idle":"2024-05-09T10:01:24.714773Z","shell.execute_reply.started":"2024-05-09T10:01:24.710647Z","shell.execute_reply":"2024-05-09T10:01:24.713851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# predictions_list = []\n\n# for index, row in df_val[:10].iterrows():\n#     print(index)\n#     row_id = row['id_EXIST']\n#     text = row['tweet']\n    \n#     prediction = get_predictions(model,text,label_dict)\n    \n#     prediction_dict = {\n#         'id': row_id,\n#         'value': prediction,\n#         'test_case':\"EXIST2024\"\n#     }\n    \n#     predictions_list.append(prediction_dict)\n\n# with open('predictions.json', 'w') as json_file:\n#     json.dump(predictions_list, json_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:24.92273Z","iopub.execute_input":"2024-05-09T10:01:24.923417Z","iopub.status.idle":"2024-05-09T10:01:24.92811Z","shell.execute_reply.started":"2024-05-09T10:01:24.923386Z","shell.execute_reply":"2024-05-09T10:01:24.927047Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:25.200661Z","iopub.execute_input":"2024-05-09T10:01:25.201495Z","iopub.status.idle":"2024-05-09T10:01:25.205694Z","shell.execute_reply.started":"2024-05-09T10:01:25.201466Z","shell.execute_reply":"2024-05-09T10:01:25.204669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_predictions(model,text,label_dict={0: 'nonsexist', 1: 'sexist'}):\n    inputs = tokenizer(text, return_tensors='pt').to(device)\n    with torch.no_grad():\n        outputs = model(inputs)\n        predictions = torch.argmax(outputs['predicts'], dim=1).cpu().numpy()\n\n    predicted_label = label_dict[predictions[0]]\n    return predicted_label\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:25.385858Z","iopub.execute_input":"2024-05-09T10:01:25.38646Z","iopub.status.idle":"2024-05-09T10:01:25.392112Z","shell.execute_reply.started":"2024-05-09T10:01:25.386434Z","shell.execute_reply":"2024-05-09T10:01:25.39109Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"NLP-LTU/bertweet-large-sexism-detector\", add_prefix_space=True)\n# base_model = AutoModel.from_pretrained(\"NLP-LTU/bertweet-large-sexism-detector\")\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\nbase_model = AutoModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\nmodel = Transformer(base_model, args.num_classes, args.method, args).to(args.device)\nmodel.load_state_dict(torch.load(args.save_path))\nlabel_dict={0: 'NO', 1: 'YES'}\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:25.604836Z","iopub.execute_input":"2024-05-09T10:01:25.605408Z","iopub.status.idle":"2024-05-09T10:01:28.119231Z","shell.execute_reply.started":"2024-05-09T10:01:25.605382Z","shell.execute_reply":"2024-05-09T10:01:28.118185Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def json_predictions(df,fname):\n    predictions_list = []\n\n    for index, row in df.iterrows():\n        row_id = row['id_EXIST']\n        text = row['tweet']\n\n        prediction = get_predictions(model,text,label_dict)\n\n        prediction_dict = {\n            'id': row_id,\n            'value': [prediction],\n            'test_case':\"EXIST2024\"\n        }\n\n        predictions_list.append(prediction_dict)\n\n    with open(fname, 'w') as json_file:\n        json.dump(predictions_list, json_file)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:28.121203Z","iopub.execute_input":"2024-05-09T10:01:28.121588Z","iopub.status.idle":"2024-05-09T10:01:28.13107Z","shell.execute_reply.started":"2024-05-09T10:01:28.12153Z","shell.execute_reply":"2024-05-09T10:01:28.129958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fname=\"team_aditya_exist2024_task1.json\"\n# json_predictions(df_dev,fname)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:01:29.232946Z","iopub.execute_input":"2024-05-09T10:01:29.23331Z","iopub.status.idle":"2024-05-09T10:01:50.978282Z","shell.execute_reply.started":"2024-05-09T10:01:29.233285Z","shell.execute_reply":"2024-05-09T10:01:50.977431Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# with open(fname,\"r\") as file:\n#     text1=json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:02:14.314558Z","iopub.execute_input":"2024-05-09T10:02:14.315389Z","iopub.status.idle":"2024-05-09T10:02:14.319193Z","shell.execute_reply.started":"2024-05-09T10:02:14.315356Z","shell.execute_reply":"2024-05-09T10:02:14.318136Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# text1","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.279127Z","iopub.status.idle":"2024-05-09T09:55:44.279464Z","shell.execute_reply.started":"2024-05-09T09:55:44.279308Z","shell.execute_reply":"2024-05-09T09:55:44.279321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Eval","metadata":{}},{"cell_type":"code","source":"# !pip install -q PyEvALL==0.1.63","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.280345Z","iopub.status.idle":"2024-05-09T09:55:44.280659Z","shell.execute_reply.started":"2024-05-09T09:55:44.280501Z","shell.execute_reply":"2024-05-09T09:55:44.280515Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from pyevall.evaluation import PyEvALLEvaluation\n# from pyevall.utils.utils import PyEvALLUtils","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.282744Z","iopub.status.idle":"2024-05-09T09:55:44.283102Z","shell.execute_reply.started":"2024-05-09T09:55:44.282923Z","shell.execute_reply":"2024-05-09T09:55:44.282937Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # predictions = \"test/hard/EXIST2024_test_task1_baseline_2.json\"\n# # gold = \"test/hard/EXIST2024_test_task1_gold_hard.json\" \n# gold = \"/kaggle/input/exist-2024/EXIST2024_dev_task1_gold_hard.json\"\n# predictions = fname\n# test = PyEvALLEvaluation()\n# params= dict() \n# params[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED \n# metrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"] \n# report= test.evaluate(predictions, gold, metrics, **params) \n# report.print_report()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.284031Z","iopub.status.idle":"2024-05-09T09:55:44.284369Z","shell.execute_reply.started":"2024-05-09T09:55:44.284199Z","shell.execute_reply":"2024-05-09T09:55:44.284213Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline Eval","metadata":{}},{"cell_type":"code","source":"def json_predictions_baseline(df):\n    predictions_list_major = []\n    predictions_list_minor = []\n\n    for index, row in df.iterrows():\n        row_id = row['id_EXIST']\n        text = row['tweet']\n\n        prediction = get_predictions(model,text,label_dict)\n\n        prediction_dict = {\n            'test_case':\"EXIST2024\",\n            'id': row_id,\n            'value': prediction,\n        }\n        if prediction=='NO':\n            predictions_list_major.append(prediction_dict)\n        else:\n            predictions_list_minor.append(prediction_dict)\n        \n#         predictions_list.append(prediction_dict)\n\n    with open('baseline_major', 'w') as json_file:\n        json.dump(predictions_list_major, json_file)\n        \n    with open(\"baseline_minor\", 'w') as json_file:\n        json.dump(predictions_list_minor, json_file)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.286438Z","iopub.status.idle":"2024-05-09T09:55:44.286794Z","shell.execute_reply.started":"2024-05-09T09:55:44.28662Z","shell.execute_reply":"2024-05-09T09:55:44.286634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # fname=\"team_aditya_exist2024_task1.json\"\n# json_predictions_baseline(df_dev)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.287796Z","iopub.status.idle":"2024-05-09T09:55:44.28813Z","shell.execute_reply.started":"2024-05-09T09:55:44.287965Z","shell.execute_reply":"2024-05-09T09:55:44.287979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gold_major=\"/kaggle/input/exist-2024/EXIST2024_dev_task1_majority_class_hard.json\"\n# gold_minor=\"/kaggle/input/exist-2024/EXIST2024_dev_task1_minority_class_hard.json\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.289655Z","iopub.status.idle":"2024-05-09T09:55:44.28999Z","shell.execute_reply.started":"2024-05-09T09:55:44.289806Z","shell.execute_reply":"2024-05-09T09:55:44.289818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # predictions = \"test/hard/EXIST2024_test_task1_baseline_2.json\"\n# # gold = \"test/hard/EXIST2024_test_task1_gold_hard.json\" \n# predictions_major=\"baseline_major\"\n# predictions_minor=\"baseline_minor\"\n# test = PyEvALLEvaluation()\n# params= dict() \n# params[PyEvALLUtils.PARAM_REPORT]= PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED \n# # metrics=[\"ICM\", \"ICMNorm\" ,\"FMeasure\"] \n# metrics=[\"FMeasure\"] \n# print(\"*****MAJOR*****\")\n# report_major= test.evaluate(predictions_major, gold_major, metrics, **params) \n# report_major.print_report()\n# print(\"*****MINOR*****\")\n# report_minor= test.evaluate(predictions_minor, gold_minor, metrics, **params) \n# report_minor.print_report()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.291187Z","iopub.status.idle":"2024-05-09T09:55:44.291487Z","shell.execute_reply.started":"2024-05-09T09:55:44.291337Z","shell.execute_reply":"2024-05-09T09:55:44.291349Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BASELINE SCORES-:\n# MAJORITY:0.6215139442231076\n# MINORITY:0.7089552238805971","metadata":{"execution":{"iopub.status.busy":"2024-05-02T13:35:17.994837Z","iopub.execute_input":"2024-05-02T13:35:17.995686Z","iopub.status.idle":"2024-05-02T13:35:17.999362Z","shell.execute_reply.started":"2024-05-02T13:35:17.995654Z","shell.execute_reply":"2024-05-02T13:35:17.998403Z"}}},{"cell_type":"code","source":"# with open(\"/kaggle/input/exist-2024/EXIST2024_dev_task1_majority_class_hard.json\",\"r\") as file:\n#     text1=json.load(file)\n# text1\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T09:55:44.292817Z","iopub.status.idle":"2024-05-09T09:55:44.293207Z","shell.execute_reply.started":"2024-05-09T09:55:44.293013Z","shell.execute_reply":"2024-05-09T09:55:44.293032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  FINAL PREDICTIONS ON TEST SET","metadata":{}},{"cell_type":"code","source":"fname=\"task1_hard_ADITYA_1.json\"\njson_predictions(df_test,fname)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T10:02:25.798412Z","iopub.execute_input":"2024-05-09T10:02:25.799099Z","iopub.status.idle":"2024-05-09T10:03:08.954908Z","shell.execute_reply.started":"2024-05-09T10:02:25.799067Z","shell.execute_reply":"2024-05-09T10:03:08.953939Z"},"trusted":true},"outputs":[],"execution_count":null}]}